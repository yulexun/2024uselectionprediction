---
title: "Prediction of 2024 US election ..."
author: 
  - Colin Sihan Yang
  - Lexun Yu
  - Siddharth Gowda
thanks: "Code and data are available at: [https://github.com/yulexun/uselection](https://github.com/yulexun/uselection)."
date: today
date-format: long
abstract: "We forecast the winner of the 2024 US presidential election using “poll-of-polls” by building a linear model."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
library(here)
library(tibble)
library(knitr)
library(arrow)
library(rstanarm)
library(brms)
```


# Introduction {#sec-intro}
Election result forecasting has become an essential tool for analysts in political science and the public to predict the outcome of democratic process, such as the presidential election in the United States. Traditionally, individual polls have been used as a snapshot of voter sentiment, but they only reflect temporary changes in the performance of contestants, instead of a precise estimation of the election result. As discussed by @pasek and @blumenthal, the aggregation of multiple polls, or "poll-of-polls," has become a popular technique to reduce individual survey errors and provide more accurate election forecasts. However, the traditional poll aggregation does not reflect dynamics of an election, especially with real-time changes and the introduction of new data. A more adaptable model is required to predict the election result based on both polling data and additional variables, such as historical data and economic indicators.

We build a hybrid election forecasting model following the strategies mentioned by @pasek. As @pasek described in their article, aggregation involves determining which surveys are worth including, as well as selecting, combining and averaging results from multiple polls to reduce individual biases and errors. Prediction modeling adds other data to the model that predicts election outcomes based on current dynamics. Hybrid models like the Bayesian approach incorporates prior beliefs based on historical data or expert knowledge and new evidence like economic updates to dynamically adjust the forecast as the campaign progresses. 

In this paper, we predict the 2024 us election result with the hybrid election forcasting model. We incorporate aggregation by filtering the polls on @fivethirtyeight by numeric grade that indicates pollster’s reliability, prediction that incorporates social and economic indicators including unemployment rates and abortion rates, and hybrid approaches that uses Bayesian techniques which combines historical data such as the 2016 election data, allowing for a dynamic prediction of the U.S. presidential election. 

The estimand for this research paper is the predicted support percentages for Kamala Harris and Donald Trump. The prediction is based on quantifying various polling factors, including sample size, poll scores, and transparency scores, which are used as predictors.

The results of this model indicate a more stable and accurate forecast compared to traditional aggregation methods alone, [update this …]

The remainder of this paper is structured as follows: [update this …]


# Data {#sec-data}

## Overview

For the data we used in this analysis about the polling result for Kamala Harris and Donalad Trump in 2024 USA president election. \
- **response variable:** pct(pct: The percentage of the vote or support that the candidate received in the poll) \
- **numeric predictor:**\
 sample size(sample_size: The total number of respondents participating in the poll) \
 timegap(the time gap between the poll start date and the real election date i.e timegap = real US election date - poll start date) \
 pollscore(A numeric value representing the score or reliability of the pollster in question) \
- **categorical predictor**
state(The U.S. state where the poll was conducted or focused) \
methodology(The method used to conduct the poll)\

## Explore the data



## Measurement

In this dataset, each row represents a polling question that records the variables of interest. Each entry allows us to explore the real-world relationships between polling factors and the support percentage (`pct`) for the candidates Kamala Harris and Donald Trump. This dataset enables an analysis of how various polling characteristics influence the reported support levels for the candidates we are focused.


## Clean Data
The data cleaning process involves several steps to ensure the quality and relevance of the polling data. First, we filter the dataset to retain only poll results with a numeric grade of 2.7 or higher, indicating that the polls are considered reliable. Next, we address missing values in the state attribute: polls with NA in the state column are considered national polls.

We then create a new attribute, days_taken_from_election, which represents the time gap between the poll's start date and the actual U.S. election date. Additionally, we filter the dataset to include only polls conducted after July 21, 2024, the date when Kamala Harris declared her candidacy. Finally, we remove any remaining rows that contain missing values to ensure a clean dataset.

```{r}
#| label: tbl-cleaned-data
#| tbl-cap: Sample of cleaned US election data 
#| echo: false
#| warning: false
cleaned_data = read_parquet(here("data/02-analysis_data/cleaned_data.parquet"))

cleaned_data |>
  select(pct, sample_size, pollscore, days_taken_from_election, state, methodology, candidate_name) |>
  head(6) |>
  kable(
    col.names = c("pct", "sample_size", "pollscore", "days_taken_from_election","state", "methodology", "candidate_name"),
    booktabs = TRUE
    ) 
```


## Basic Statistics Summary for Data

```{r}
#| label: fig-clean-data-histogram-Harris-Trump
#| fig-cap: the average PCT vs State for Harris and Trump
#| echo: false
#| warning: false
#| fig-subcap: ["average PCT vs State for Harris","PCT vs State for Trump"]
#| layout-nrow: 2
#| fig-width: 40
#| fig-height: 20
Harris_data = cleaned_data[cleaned_data$candidate_name == "Kamala Harris", ]
Harris_data |>
  group_by(state) |>
  summarise(avg_pct = mean(pct, na.rm = TRUE)) |>
  ggplot(mapping = aes(x = state, y = avg_pct)) + 
  geom_col()  +
  theme_minimal() +
  labs(
    x = "State", y = "support percentage(pct)", title = "average support percentage(pct) for Harris per state"
  )


Trump_data = cleaned_data[cleaned_data$candidate_name == "Donald Trump", ]
Trump_data |>
  group_by(state) |>
  summarise(avg_pct = mean(pct, na.rm = TRUE)) |>
  ggplot(mapping = aes(x = state, y = avg_pct)) + 
  geom_col()  +
  theme_minimal() +
  labs(
    x = "State", y = "support percentage(pct)", title = "average support percentage(pct) for Harris per state"
  )


# cleaned_data %>%
#   mutate(month = factor(month, levels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
#                                           "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))) %>%
#   ggplot(mapping = aes(x = month, y = total_decedents)) + 
#   geom_bar(stat = "identity") +
#   theme_minimal() +
#   labs(
#     x = "Month", 
#     y = "Total Decedents"
#   )
```


# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.
us

## Basic Model
```{r}
just_harris_data = Harris_data |> na.omit()
model_MLR = lm(pct ~ pollscore + days_taken_from_election + methodology, data = just_harris_data)
summary(model_MLR)
just_harris_data <- just_harris_data |> mutate(fitted_value = predict(model_MLR),  num_harris = round((pct / 100) * sample_size, 0))

predictions = predict(model_MLR, just_harris_data)

ggplot(just_harris_data, aes(x = end_date)) +
  geom_point(aes(y = pct), color = "black") +
  geom_line(aes(y = fitted_value), color = "blue", linetype = "dotted") +
  facet_wrap(vars(methodology)) +
  theme_classic() +
  labs(y = "Harris percent", x = "Date", title = "Linear Model: pct ~ end_date + pollster")
```

```{r}
baye_model_data = just_harris_data
baye_model_data$pct = as.factor(baye_model_data$pct)
baye_model_data$pollscore = as.factor(baye_model_data$pollscore)
baye_model_data$days_taken_from_election = as.factor(baye_model_data$days_taken_from_election)
baye_model_data$methodology = as.factor(baye_model_data$methodology)
baye_model_data$pct <- as.numeric(baye_model_data$pct)
# Define the Bayesian model with brms

formula <- pct ~ pollscore + days_taken_from_election + (1 | methodology) + (1 | state)

priors = normal(0, 2.5, autoscale = TRUE)

bayesian_model_1 <- stan_glmer(
  formula = formula,
  data = just_harris_data,
  family = gaussian(),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  cores = 4,
  adapt_delta = 0.95
)
pp_check(bayesian_model_1)
summary(bayesian_model_1)

# Plot random effects
plot(bayesian_model_1, pars = "(Intercept)", prob = 0.95)

```


```{r}


# Transform Biden and Trump’s vote shares to fit a beta distribution
# Biden received 51.3%, Trump received 46.8%, totaling to approximately 98.1% (adjusted here for simplicity)
total_votes <- 100
biden_shape1 <- 51.3 / total_votes * 10
biden_shape2 <- (1 - 51.3 / total_votes) * 10
trump_shape1 <- 46.8 / total_votes * 10
trump_shape2 <- (1 - 46.8 / total_votes) * 10

# Set up priors using beta distributions based on 2020 vote shares
# prior <- c(
#   set_prior(paste0("beta(", biden_shape1, ", ", biden_shape2, ")"), class = "b", coef = "biden"),
#   set_prior(paste0("beta(", trump_shape1, ", ", trump_shape2, ")"), class = "b", coef = "trump")
# )

prior <- c(
  set_prior(beta(biden_shape1, biden_shape2), class = "b", coef = "biden"),
  set_prior(beta(trump_shape1, trump_shape2), class = "b", coef = "trump"))

# Define the model formula

formula1 <- pct ~ pollscore + days_taken_from_election + methodology

# Run the Bayesian model
model <- brm(
  formula = formula1,
  data = baye_model_data,
  family = categorical(),
  prior = prior,
  chains = 4,
  iter = 2000,
  warmup = 1000,
  cores =4
)

# Summarize the model
summary(model)

```

# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.
us


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

# Methodology of YouGov
YouGov's methodology documentations are seperated in two articles. The article by @bailey_how_2024 documents the methodology of the 2024 election projection, while the webpage on @yougov_methodology_nodate documents the general methodology of YouGov's prediction.

## Population, Frame, and Sample
As @bailey_how_2024 stated, the population covered by YouGov's MRP model is everyone in the national voter file, whether or not they belong to YouGov's panel. The national voter files are digital database built by commercial organizations with public government records of voters, as explained by @desilver_q_2018. Voter files indicates whether asomeone voted in a given election, thus YouGov's population covers all voters in previous US elections. 

YouGov’s sampling frame consists of its online panel members. These members are part of the SAY24 project, a collaboration between Stanford, Arizona State, and Yale Universities, as stated by @bailey_how_2024. YouGov collect information on respondents when they join their panel before they are invited to participate in the survey.

YouGov select the sample from the sampling frame based on their ability to match characteristics of the population of interest. YouGov interviews nearly 100,000 people in the first set of estimates. For the second set of estimates, YouGov didn't just start over with a new sample. They took the initial data from August and September and updated it with responses from more than 20,000 additional registered voters who were re-interviewed in late September and early October.

## Sample Recruitment
Panelists are recruited through various online channels, including advertisements and partnerships with websites [@yougov_methodology_nodate]. They must provide demographic details upon joining, which helps in selecting representative samples for each survey. When respondents complete a survey, they are awarded points that can be exchanged for money.

## Sampling Approach and Trade-offs
YouGov uses non-probability sampling due to the compensation, an approach where not every individual has an equal chance of selection [@yougov_methodology_nodate]. This method allows quick and cost-effective data collection. However, as @yougov_methodology_nodate writes the panelists must have an internet connection to participate. YouGov state that there is 95% of us population with internet access, thus the sample may be less representative of certain hard-to-reach populations, such as individuals with very slow internet access or without internet access. 

## Non-response Handling
YouGov apply statistical weighting to adjust for the differences between the sample and target population. The weight is based on demographic characteristics such as age, gender, race and presidential vote [@yougov_methodology_nodate]. Additionally, quality control measures exclude unreliable responses to improve data accuracy. The respondents are offered a small incentive to decrease the non-response and increase participation.

## Strengths and Weaknesses of the Questionnaire
YouGov's surveys are conducted online, which is very efficient for the respondents, and responses are weighted to enhance representativeness. The pollster can recruit a large amount of panelists because of the online format. Combining with online tracking technologies, the metadata provided by ther panelists can be verified easily.

As a non-probability sample, it might miss certain demographic groups not covered by the online population. While weighting improves accuracy, it cannot fully substitute the randomization found in probability sampling​. Additionaly, the categories in the surbey is oversimplified with bias. For instance, in the poll result published by YouGov, gender is divided into Male and Female. Race is divided into White, Black, Hispanic and Other. This indicates a lack of representation. 

# FiveThirtyEight Licenses
[FiveThirtyEight's data sets](https://github.com/fivethirtyeight/data/tree/master/polls) are used and modified by us under the [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).

\newpage


# References


