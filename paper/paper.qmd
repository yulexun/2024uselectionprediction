---
title: "Prediction of 2024 US election ..."
author: 
  - Colin Sihan Yang
  - Lexun Yu
  - Siddharth Gowda
thanks: "Code and data are available at: [https://github.com/yulexun/uselection](https://github.com/yulexun/uselection)."
date: today
date-format: long
abstract: "We forecast the winner of the 2024 US presidential election using “poll-of-polls” by building a linear model."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
library(here)
library(tibble)
library(knitr)
library(brms)
library(rstanarm)
library(gridExtra)
```

```{r}
cleaned_data = read_csv(here("data/02-analysis_data/cleaned_data.csv"))
```

# Introduction {#sec-intro}
Election result forecasting has become an essential tool for analysts in political science and the public to predict the outcome of democratic process, such as the presidential election in the United States. Traditionally, individual polls have been used as a snapshot of voter sentiment, but they only reflect temporary changes in the performance of contestants, instead of a precise estimation of the election result. As discussed by @pasek and @blumenthal, the aggregation of multiple polls, or "poll-of-polls," has become a popular technique to reduce individual survey errors and provide more accurate election forecasts. However, the traditional poll aggregation does not reflect dynamics of an election, especially with real-time changes and the introduction of new data. This creates a gap for a more adaptable model to predict the election result based on both polling data and additional variables, such as historical data and economic indicators.

This paper fills the gap by building a hybrid election forecasting model following the strategies mentioned by @pasek. As @pasek described in their article, aggregation involves determining which surveys are worth including, as well as selecting, combining and averaging results from multiple polls to reduce individual biases and errors. Prediction modeling adds other data to the model that predicts election outcomes based on current dynamics. Hybrid models like the Bayesian approach incorporates prior beliefs based on historical data or expert knowledge and new evidence like economic updates to dynamically adjust the forecast as the campaign progresses. 

In this paper, we aim to predict the 2024 us election result with the hybrid election forcasting model. We incorporate aggregation by filtering the polls on @fivethirtyeight by numeric grade that indicates pollster’s reliability, prediction that incorporates social and economic indicators including unemployment rates and abortion rates, and hybrid approaches that leverages Bayesian techniques which combines historical data such as the 2016 election data, allowing for a dynamic prediction of the U.S. presidential election. 

The estimand for this research paper is the predicted support percentages for Kamala Harris and Donald Trump. The prediction is based on quantifying various polling factors, including sample size, poll scores, and transparency scores, which are used as predictors.

The results of this model indicate a more stable and accurate forecast compared to traditional aggregation methods alone, [update this …]

The remainder of this paper is structured as follows: [update this …]


# Data {#sec-data}

## Overview

For the data we used in this analysis about the polling result for Kamala Harris and Donalad Trump in 2024 USA president election. \
- **response variable:** `pct`(pct: The percentage of the vote or support that the candidate received in the poll) \
- **numeric predictor:**\
 `sample size`(sample_size: The total number of respondents participating in the poll) \
 `timegap`(the time gap between the poll start date and the real election date i.e timegap = real US election date - poll start date) \
 `pollscore`(A numeric value representing the score or reliability of the pollster in question) \
- **categorical predictor**
`state`(The U.S. state where the poll was conducted or focused) \
`methodology`(The method used to conduct the poll)\

## Explore the data
```{r}
#| label: tbl-explore-data
#| echo: false
#| warning: false
a <- ggplot(data=cleaned_data, aes(x=sample_size, y=pct)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(x = 'sample size', y='pct', 
       title = 'pct vs sample size')

b <- ggplot(data=cleaned_data, aes(x=pollscore, y=pct)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(x = 'pollscore', y='pct', 
       title = 'pct vs pollscore')

c <- ggplot(data=cleaned_data, aes(x=methodology, y=pct)) + 
  geom_boxplot() + 
  labs(x = 'wind speed', y='pct', 
       title = 'pct vs methodology')

d <- ggplot(data=cleaned_data, aes(x=days_taken_from_election, y=pct)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(x = 'max gust speed', y='pct', 
       title = 'pct vs days taken from election')

e <- ggplot(data=cleaned_data, aes(x=state, y=pct)) + 
  geom_boxplot() + 
  labs(x = 'total snow', y='pct', 
       title = 'pct vs state')

grid.arrange(a, b, c, d, e, nrow=2)
```

- pct vs sample size: This scatter plot shows the pct against the sample size, with a fitted trend line indicating a slight positive relationship. The data points are denser for lower sample sizes, suggesting that smaller sample sizes are more common in the dataset.

- pct vs pollscore: This scatter plot illustrates the pct against pollscore. The fitted trend line suggests a weak negative relationship between pollscore and pct. The points are scattered without a strong linear pattern.

- pct vs methodology: A boxplot comparing pct for different polling methodologies. The pct distribution varies across methodologies, with some showing greater spread or median differences. This suggests that the polling methodology may influence pct outcomes.

- pct vs days taken from election: A scatter plot displaying pct versus the number of days before the election. The trend line indicates a slight negative relationship, suggesting that as the election date approaches, pct may decrease slightly.

- pct vs state: A boxplot depicting pct across different states. The pct distribution varies by state, with some states showing wider variability or different median values, implying state-specific effects on pct.



```{r}
# numeric_data <- cleaned_data[sapply(cleaned_data, is.numeric)]
numeric_data = cleaned_data |> select(pct, sample_size, pollscore, days_taken_from_election)

# Create the pairs plot
pairs(numeric_data)
```

The pairs plot displays scatter plots of four numeric variables (`pct`, `sample_size`, `pollscore`, and `days_taken_from_election`) to visualize their relationships. The data shows clustering, particularly in `pct` versus `sample_size`, suggesting potential heteroscedasticity. The `sample_size` variable is skewed towards lower values, while `pollscore` and `days_taken_from_election` have a more even spread, though `pollscore` shows central clustering. No strong linear relationships are immediately apparent between the variables, indicating that correlations are likely weak. 

## Measurement

In this dataset, each row represents a polling question that records the variables of interest. Each entry allows us to explore the real-world relationships between polling factors and the support percentage (`pct`) for the candidates Kamala Harris and Donald Trump. This dataset enables an analysis of how various polling characteristics influence the reported support levels for the candidates we are focused.


## Clean Data
The data cleaning process involves several steps to ensure the quality and relevance of the polling data. First, we filter the dataset to retain only poll results with a numeric grade of 2.7 or higher, indicating that the polls are considered reliable. Next, we address missing values in the state attribute: polls with NA in the state column are considered national polls.

We then create a new attribute, days_taken_from_election, which represents the time gap between the poll's start date and the actual U.S. election date. Additionally, we filter the dataset to include only polls conducted after July 21, 2024, the date when Kamala Harris declared her candidacy. Finally, we remove any remaining rows that contain missing values to ensure a clean dataset.

```{r}
#| label: tbl-cleaned-data
#| tbl-cap: Sample of cleaned US election data 
#| echo: false
#| warning: false

cleaned_data |>
  select(pct, sample_size, pollscore, days_taken_from_election, state, methodology, candidate_name) |>
  head(6) |>
  kable(
    col.names = c("pct", "sample_size", "pollscore", "days_taken_from_election","state", "methodology", "candidate_name"),
    booktabs = TRUE
    ) 
```


## Basic Statistics Summary for Data

```{r}
#| label: fig-clean-data-histogram-Harris-Trump
#| fig-cap: the average PCT vs State for Harris and Trump
#| echo: false
#| warning: false
#| fig-subcap: ["average PCT vs State for Harris","PCT vs State for Trump"]
#| layout-nrow: 2
#| fig-width: 40
#| fig-height: 20
Harris_data = cleaned_data[cleaned_data$candidate_name == "Kamala Harris", ]
Harris_data |>
  group_by(state) |>
  summarise(avg_pct = mean(pct, na.rm = TRUE)) |>
  ggplot(mapping = aes(x = state, y = avg_pct)) + 
  geom_col()  +
  theme_minimal() +
  labs(
    x = "State", y = "support percentage(pct)", title = "average support percentage(pct) for Harris per state"
  )


Trump_data = cleaned_data[cleaned_data$candidate_name == "Donald Trump", ]
Trump_data |>
  group_by(state) |>
  summarise(avg_pct = mean(pct, na.rm = TRUE)) |>
  ggplot(mapping = aes(x = state, y = avg_pct)) + 
  geom_col()  +
  theme_minimal() +
  labs(
    x = "State", y = "support percentage(pct)", title = "average support percentage(pct) for Harris per state"
  )


# cleaned_data %>%
#   mutate(month = factor(month, levels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
#                                           "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))) %>%
#   ggplot(mapping = aes(x = month, y = total_decedents)) + 
#   geom_bar(stat = "identity") +
#   theme_minimal() +
#   labs(
#     x = "Month", 
#     y = "Total Decedents"
#   )
```



# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.
us

## Basic Model
```{r}
#| echo: false
#| warning: false
just_harris_data = Harris_data |> na.omit()
lm_model1 = lm(pct ~ pollscore, data = just_harris_data)
predictions = predict(lm_model1, just_harris_data)
summary(lm_model1)

ggplot(just_harris_data, aes(x = pct, y = predictions)) +
  geom_point(color = 'blue') +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(title = "Actual vs Predicted Values",
       x = "Actual pct",
       y = "Predicted pct") +
  theme_minimal()

```


```{r}
#| echo: false
#| warning: false
just_harris_data = Harris_data |> na.omit()
model_MLR = lm(pct ~ pollscore + days_taken_from_election + methodology + sample_size + state, data = just_harris_data)
summary(model_MLR)
just_harris_data <- just_harris_data |> mutate(fitted_value = predict(model_MLR),  num_harris = round((pct / 100) * sample_size, 0))

predictions = predict(model_MLR, just_harris_data)

ggplot(just_harris_data, aes(x = end_date)) +
  geom_point(aes(y = pct), color = "black") +
  geom_line(aes(y = fitted_value), color = "blue", linetype = "dotted") +
  facet_wrap(vars(methodology)) +
  theme_classic() +
  labs(y = "Harris percent", x = "Date", title = "Linear Model: pct ~ end_date + pollster")
```

```{r}
#| echo: false
#| warning: false
ggplot(just_harris_data, aes(x = pct, y = fitted_value)) +
  geom_point(color = 'blue') +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(title = "Actual vs Predicted Values",
       x = "Actual pct",
       y = "Predicted pct") +
  theme_minimal()
```



```{r}
baye_model_data = just_harris_data
baye_model_data$pct = as.factor(baye_model_data$pct)
baye_model_data$pollscore = as.factor(baye_model_data$pollscore)
baye_model_data$days_taken_from_election = as.factor(baye_model_data$days_taken_from_election)
baye_model_data$methodology = as.factor(baye_model_data$methodology)
baye_model_data$pct <- as.numeric(baye_model_data$pct)
# Define the Bayesian model with brms

formula <- pct ~ pollscore + days_taken_from_election + (1 | methodology) + (1 | state)

priors = normal(0, 2.5, autoscale = TRUE)

bayesian_model_1 <- stan_glmer(
  formula = formula,
  data = just_harris_data,
  family = gaussian(),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  cores = 4,
  adapt_delta = 0.95
)
pp_check(bayesian_model_1)
summary(bayesian_model_1)
```

This plot displays the results of a posterior predictive check (PPC) for a Bayesian model using the pp_check() function. 

The observed data (y) follows a distinct, symmetrical distribution centered around a specific value, suggesting a well-defined peak with tapering on both sides. The replicated distributions (y_rep), shown as multiple thin lines, generally align with the shape of the observed distribution, indicating that the Bayesian model has captured the main characteristics of the data. However, the variability in the y_rep lines highlights the degree of uncertainty inherent in the model’s predictive capability.

The fact that the y_rep curves closely match the overall pattern of the actual y suggests that the model performs reasonably well in replicating the observed data. Minor discrepancies or deviations between the y and y_rep might imply areas where the model could be fine-tuned or adjusted to improve accuracy. Overall, this PPC indicates that the model provides a decent fit to the data, with some variability accounted for in the predictive samples.


```{r}
# Plot random effects
plot(bayesian_model_1, pars = "(Intercept)", prob = 0.95)
```

This plot displays the estimated posterior distribution for the intercept parameter in the Bayesian model. The intercept represents the baseline level of support, expressed as a percentage, for Kamala Harris in the U.S. election data used in the analysis. The plot features a point estimate (depicted by the central dot) that indicates the mean or median of the posterior distribution for the intercept, and a horizontal line showing the 95% credible interval, which signifies the range within which the true value of the intercept is likely to fall with 95% probability.

The range of this credible interval spans from approximately 50 to 54 percent, suggesting that the model estimates the baseline level of support for Kamala Harris to be around this range. The relatively narrow width of the interval implies a certain degree of confidence in the estimate, indicating that the data used in the model provided a clear signal for the intercept's value.

In conclusion, the estimated intercept, which represents the baseline percentage of support for Kamala Harris in the U.S. election data analyzed, is centered around 52%, with a credible interval spanning approximately from 50% to 54%. This suggests that, according to the Bayesian model, the underlying support for Kamala Harris.


```{r}


# # Transform Biden and Trump’s vote shares to fit a beta distribution
# # Biden received 51.3%, Trump received 46.8%, totaling to approximately 98.1% (adjusted here for simplicity)
# total_votes <- 100
# biden_shape1 <- 51.3 / total_votes * 10
# biden_shape2 <- (1 - 51.3 / total_votes) * 10
# trump_shape1 <- 46.8 / total_votes * 10
# trump_shape2 <- (1 - 46.8 / total_votes) * 10

# # Set up priors using beta distributions based on 2020 vote shares
# prior <- c(
#   set_prior(paste0("beta(", biden_shape1, ", ", biden_shape2, ")"), class = "b", coef = "biden"),
#   set_prior(paste0("beta(", trump_shape1, ", ", trump_shape2, ")"), class = "b", coef = "trump")
# )

# # Define the model formula
# formula <- pct ~ pollscore + days_taken_from_election + methodology

# # Run the Bayesian model
# model <- brm(
#   formula = formula,
#   data = baye_model_data,
#   family = categ0orical(),
#   prior = prior,
#   chains = 4,
#   iter = 2000,
#   warmup = 1000,
#   cores =4
# )

# # Summarize the model
# summary(model)

```


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

# FiveThirtyEight Licenses
[FiveThirtyEight's data sets](https://github.com/fivethirtyeight/data/tree/master/polls) are used and modified by us under the [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).

\newpage


# References


