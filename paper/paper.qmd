---
title: "Prediction of 2024 US election ..."
author: 
  - Colin Sihan Yang
  - Lexun Yu
  - Siddharth Gowda
thanks: "Code and data are available at: [https://github.com/yulexun/uselection](https://github.com/yulexun/uselection)."
date: today
date-format: long
abstract: "We forecast the winner of the 2024 US presidential election using “poll-of-polls” by building a linear model."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
library(here)
library(tibble)
library(knitr)
library(brms)
library(rstanarm)
library(gridExtra)
library(Matrix)
library(rstan)
library(brms)

```

```{r}
#| echo: false
#| warning: false
cleaned_data = read_csv(here("data/02-analysis_data/cleaned_data.csv"))
```

# Introduction {#sec-intro}
Election result forecasting has become an essential tool for analysts in political science and the public to predict the outcome of democratic process, such as the presidential election in the United States. Traditionally, individual polls have been used as a snapshot of voter sentiment, but they only reflect temporary changes in the performance of contestants, instead of a precise estimation of the election result. As discussed by @pasek and @blumenthal, the aggregation of multiple polls, or "poll-of-polls," has become a popular technique to reduce individual survey errors and provide more accurate election forecasts. However, the traditional poll aggregation does not reflect dynamics of an election, especially with real-time changes and the introduction of new data. This creates a gap for a more adaptable model to predict the election result based on both polling data and additional variables, such as historical data and economic indicators.

This paper fills the gap by building a hybrid election forecasting model following the strategies mentioned by @pasek. As @pasek described in their article, aggregation involves determining which surveys are worth including, as well as selecting, combining and averaging results from multiple polls to reduce individual biases and errors. Prediction modeling adds other data to the model that predicts election outcomes based on current dynamics. Hybrid models like the Bayesian approach incorporates prior beliefs based on historical data or expert knowledge and new evidence like economic updates to dynamically adjust the forecast as the campaign progresses. 

In this paper, we aim to predict the 2024 us election result with the hybrid election forcasting model. We incorporate aggregation by filtering the polls on @fivethirtyeight by numeric grade that indicates pollster’s reliability, prediction that incorporates social and economic indicators including unemployment rates and abortion rates, and hybrid approaches that leverages Bayesian techniques which combines historical data such as the 2016 election data, allowing for a dynamic prediction of the U.S. presidential election. 

The estimand for this research paper is the predicted support percentages for Kamala Harris and Donald Trump. The prediction is based on quantifying various polling factors, including sample size, poll scores, and transparency scores, which are used as predictors.

The results of this model indicate a more stable and accurate forecast compared to traditional aggregation methods alone, [update this …]

The remainder of this paper is structured as follows: [update this …]

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

# FiveThirtyEight Licenses
[FiveThirtyEight's data sets](https://github.com/fivethirtyeight/data/tree/master/polls) are used and modified by us under the [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).

# Trump Voter Prediction Model

The multiple linear regression model (MLR) for Donald Trump will use the same variables, formula, and Bayesian approach as the one for Harris. Likewise, the Trump dataset is also split into training and testing data. The model outputs are below.

```{r}
#| echo: false
#| warning: false
set.seed(123)
train_data_trump <- read_csv(here("data/02-analysis_data/train_data_trump.csv"))
test_data_trump <- read_csv(here("data/02-analysis_data/test_data_trump.csv"))
bayesian_model_train_trump <- readRDS(here("models/bayesian_model_train_trump.rds"))
```

```{r}
#| label: fig-model-trumpmlr
#| fig-cap: "MLR Trump Model Accounts For A Large Amount of Variability in Voter Percentage"
#| echo: false
#| warning: false

just_trump <- cleaned_data %>% filter(candidate_name == "Donald Trump")

predictions2 = posterior_predict(bayesian_model_train_trump, newdata = just_trump)

predicted_means = colMeans(predictions2)
predicted_intervals = apply(predictions2, 2, quantile, probs = c(0.025, 0.975))

result_summary = data.frame(
  Actual_PCT = just_trump$pct,
  Predicted_PCT = predicted_means,
  Lower_CI = predicted_intervals[1, ],
  Upper_CI = predicted_intervals[2, ]
)

# kable(head(result_summary, 10), caption = "Head of Bayesian Model Result Summary")

ggplot(result_summary, aes(x = result_summary$Actual_PCT, y = result_summary$Predicted_PCT)) +
  geom_point(color = "blue", alpha = 0.7) +
  # geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2, color = "blue") +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    title = "Actual vs Predicted Percentage For Trump MLR Model (All Trump Data)",
    x = "Actual PCT",
    y = "Predicted PCT"
  )
```
From @fig-model-trumpmlr it is clear that the model accounts for large amount of the variance in Trump's voter percentage as the data points appear close to the prediction (red line). Furthermore, the distance between the prediction and the actual values do not appear to follow a pattern, suggesting that the error is due to randomness and not model bias.

```{r}
#| label: fig-model-trumpmlr-res
#| fig-cap: "MLR Trump Model does not Appear to Overfit"
#| echo: false
#| warning: false

predictions2 = posterior_predict(bayesian_model_train_trump, newdata = test_data_trump)

plot(test_data_trump$pct, colMeans(predictions2), 
     xlab = "Actual PCT Values", 
     ylab = "Predicted  PCT Values", 
     main = "Predicted PCT vs Actual PCT (Test Data)")
abline(0, 1, col = "red")  # Add a 45-degree reference line

```
Based on @fig-model-trumpmlr-res, the test data predictions are also close to the actual values. This suggests that model can generalization to outside data. Similarly, the distance between the prediction and the actual values do not appear to follow a pattern, suggesting that the error is due to randomness and not model bias. 



```{r}
#| label: fig-trumpmodelci
#| fig-cap: Donald Trump Expected to Recieve Approximatley 45% of the Vote
#| echo: false
#| warning: false

plot(bayesian_model_train_trump, pars = "(Intercept)", prob = 0.95)
```
Based on @fig-trumpmodelci, the model expects Trump to win slight less than 45% of the popular vote and the 95% confidence interval ranges from around 42.5% to 47.2%. This confidence interval is slightly larger than the model for Harris, implying that the Trump polling data might be less reliable.

# Election Prediction

Our prediction process consists of two primary components. First, we develop models for both Trump and Harris based on the variables outlined in Section @sec-PLACEHOLDER. This involves partitioning the dataset into training and testing subsets. Next, we further divide the testing dataset into swing states and other competitive races. We then input this test data into the respective models to generate predictions. By averaging these predictions, we can calculate the expected voter percentage for each candidate in each state. The candidate with the higher percentage is deemed the winner for that state.

We generated predictions for the following states: Arizona, Nevada, Georgia, Pennsylvania, Michigan, Minnesota, Wisconsin, Florida, Texas, Maine CD-2, Nebraska CD-2, New Hampshire, Ohio, Virginia, North Carolina, and Iowa. Winners for other states were determined based on historical trends and predictions from sources like @cnn. Most states without predictions are strongly Republican or Democratic, so their absence is not expected to significantly impact prediction validity.
```{r}
#| echo: false
#| warning: false
#| label: tbl-electionprediction
#| tbl-cap: Kamala Harris Wins Most of the Swing States
# Split data into training and test sets

train_data_harris <- read_csv(here("data/02-analysis_data/train_data_harris.csv"))
test_data_harris <- read_csv(here("data/02-analysis_data/test_data_harris.csv"))
bayesian_model_train_harris <- readRDS(here("models/bayesian_model_train_harris.rds"))

relevant_states <- c("Arizona", "Nevada", "Georgia", "Pennsylvania", "Michigan", "Minnesota",
                     "Wisconsin", "Florida", "Texas", "Maine CD-2", "Nebraska CD-2", 
                     "New Hampshire", "Ohio", "Virginia", "North Carolina", "Iowa")

# Initialize an empty tibble to store results
swing_state_predictions <- tibble(
  state = character(),
  harris_predicted_pct = numeric(),
  trump_predicted_pct = numeric(),
  winner = character()
)

for(state in relevant_states) {
  #print(state, state %in% unique(test_data_trump), state %in% unique(test_data_harris))
  test_data_state_harris <- test_data_harris[test_data_harris$state == state, ]
  test_data_state_trump <- test_data_trump[test_data_trump$state == state, ]
  
  predictions_state_harris <- posterior_predict(bayesian_model_train_harris, newdata = test_data_state_harris)
  predictions_state_trump <- posterior_predict(bayesian_model_train_trump, newdata = test_data_state_trump)
  
  avg_predicted_pct_state_harris <- mean(predictions_state_harris)
  avg_predicted_pct_state_trump <- mean(predictions_state_trump)
  
  # Add a new row to the results tibble
  new_row <- tibble(
    state = state,
    harris_predicted_pct = avg_predicted_pct_state_harris,
    trump_predicted_pct = avg_predicted_pct_state_trump,
    winner = ifelse(trump_predicted_pct > harris_predicted_pct, "Trump", "Harris")
  )
  # print(state)
  # print(avg_predicted_pct_state_harris)
  # print(avg_predicted_pct_state_trump)
  # 
  swing_state_predictions <- bind_rows(swing_state_predictions, new_row)
}

swing_state_predictions <- swing_state_predictions %>% arrange(state) %>% unique()

# View the results
swing_state_predictions %>% 
  kable(col.names = 
          c("State", "Harris Predicted Percentage", 
            "Trump Predicted Percentage", "State Winner"))
  
```


```{r}
#| label: fig-electionpredictionmap
#| fig-cap: Kamala Harris is Predicited to be the 47th President of the United States
#| echo: false
#| warning: false

# Define your colors for each state (replace these colors with your desired ones)
state_colors_legend <- c(
  "Republican" = "red",      # Dark Red
  "Democrat" = "blue",        # Dark Blue
  "Split By District" = "gray"
)

purple = "purple"
light_blue = "green"
light_red = "orange"

state_colors <- c(
  alabama = "red",
  arizona = ifelse((swing_state_predictions %>% 
                        filter(state == "Arizona") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  arkansas = "red",
  california = "blue",
  colorado = "blue",
  connecticut = "blue",
  delaware = "blue",
  `district of columbia` = "blue",
  florida = ifelse((swing_state_predictions %>% 
                        filter(state == "Florida") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  georgia = ifelse((swing_state_predictions %>% 
                        filter(state == "Georgia") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  idaho = "red",
  illinois = "blue",
  indiana = "red",
  iowa = ifelse((swing_state_predictions %>% 
                        filter(state == "Iowa") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  kansas = "red",
  kentucky = "red",
  louisiana = "red",
  maine = "gray",
  maryland = "blue",
  massachusetts = "blue",
  michigan = ifelse((swing_state_predictions %>% 
                        filter(state == "Michigan") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  minnesota = ifelse((swing_state_predictions %>% 
                        filter(state == "Minnesota") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  mississippi = "red",
  missouri = "red",
  montana = "red",
  nebraska = "gray",
  nevada = ifelse((swing_state_predictions %>% 
                        filter(state == "Nevada") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  `new hampshire` = ifelse((swing_state_predictions %>% 
                        filter(state == "New Hampshire") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  `new jersey` = "blue",
  `new mexico` = "blue",
  `new york` = "blue",
  `north carolina` = ifelse((swing_state_predictions %>% 
                        filter(state == "North Carolina") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  `north dakota` = "red",
  ohio = ifelse((swing_state_predictions %>% 
                        filter(state == "Ohio") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  oklahoma = "red",
  oregon = "blue",
  pennsylvania = ifelse((swing_state_predictions %>% 
                        filter(state == "Pennsylvania") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  `rhode island` = "blue",
  `south carolina` = "red",
  `south dakota` = "red",
  tennessee = "red",
  texas = ifelse((swing_state_predictions %>% 
                        filter(state == "Texas") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  utah = "red",
  vermont = "blue",
  virginia = ifelse((swing_state_predictions %>% 
                        filter(state == "Virginia") %>% 
                        select(winner)) == "Trump", "red", "blue"),
  washington = "blue",
  `west virginia` = "red",
  wisconsin = ifelse((swing_state_predictions %>% 
                        filter(state == "Wisconsin") %>% 
                        select(winner)) == "Trump", "red", "blue"), 
  wyoming = "red")

# Load the states map data
states_map <- map_data(map = "state")

state_colors <- setNames(state_colors, tolower(names(state_colors)))

color_to_status <- setNames(names(state_colors_legend), state_colors_legend)

states_map <- states_map %>%
  mutate(status = color_to_status[state_colors[region]])

plotclr <- c("red", gray, "blue")
legend_description <- c(
  "Republican",
  "Democrat",
  "Split by District"
)


ggplot(states_map, aes(x = long, y = lat, group = group, fill = status)) +
  geom_polygon(color = "white", size = 0.2) +
  coord_map("albers", lat0 = 39, lat1 = 45) +
  scale_fill_manual(
    values = state_colors_legend,
    name = "Election Status"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 10),
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank()
  )

```
According to Figure @fig-currentstateofelection, Kamala Harris is predicted to be the 47th President of the United States. There are also a few states with predictions not visible in the map, we will describe those predicts them below 

In Maine, Harris is projected to win the state’s overall delegates and District 1, while District 2 is expected to go to Trump. In Nebraska, Trump is expected to win the state’s delegates along with Districts 1 and 3, while Harris is predicted to win District 2. Additionally, Trump is projected to win Alaska, and Harris is expected to win Hawaii.

Overall, the predictions indicate that Harris will receive 298 delegates, while Trump will receive 240 delegates.

\newpage


# References
