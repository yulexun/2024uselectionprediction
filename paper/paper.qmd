---
title: "Prediction of 2024 US election ..."
author: 
  - Colin Sihan Yang
  - Lexun Yu
  - Siddharth Gowda
thanks: "Code and data are available at: [https://github.com/yulexun/uselection](https://github.com/yulexun/uselection)."
date: today
date-format: long
abstract: "We forecast the winner of the 2024 US presidential election using “poll-of-polls” by building a linear model."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
library(here)
library(tibble)
library(knitr)
library(brms)
library(rstanarm)
```


# Introduction {#sec-intro}
Election result forecasting has become an essential tool for analysts in political science and the public to predict the outcome of democratic process, such as the presidential election in the United States. Traditionally, individual polls have been used as a snapshot of voter sentiment, but they only reflect temporary changes in the performance of contestants, instead of a precise estimation of the election result. As discussed by @pasek and @blumenthal, the aggregation of multiple polls, or "poll-of-polls," has become a popular technique to reduce individual survey errors and provide more accurate election forecasts. However, the traditional poll aggregation does not reflect dynamics of an election, especially with real-time changes and the introduction of new data. This creates a gap for a more adaptable model to predict the election result based on both polling data and additional variables, such as historical data and economic indicators.

This paper fills the gap by building a hybrid election forecasting model following the strategies mentioned by @pasek. As @pasek described in their article, aggregation involves determining which surveys are worth including, as well as selecting, combining and averaging results from multiple polls to reduce individual biases and errors. Prediction modeling adds other data to the model that predicts election outcomes based on current dynamics. Hybrid models like the Bayesian approach incorporates prior beliefs based on historical data or expert knowledge and new evidence like economic updates to dynamically adjust the forecast as the campaign progresses. 

In this paper, we aim to predict the 2024 us election result with the hybrid election forcasting model. We incorporate aggregation by filtering the polls on @fivethirtyeight by numeric grade that indicates pollster’s reliability, prediction that incorporates social and economic indicators including unemployment rates and abortion rates, and hybrid approaches that leverages Bayesian techniques which combines historical data such as the 2016 election data, allowing for a dynamic prediction of the U.S. presidential election. 

The estimand for this research paper is the predicted support percentages for Kamala Harris and Donald Trump. The prediction is based on quantifying various polling factors, including sample size, poll scores, and transparency scores, which are used as predictors.

The results of this model indicate a more stable and accurate forecast compared to traditional aggregation methods alone, [update this …]

The remainder of this paper is structured as follows: [update this …]


# Data {#sec-data}

## Overview

For the data we used in this analysis about the polling result for Kamala Harris and Donalad Trump in 2024 USA president election. \
- **response variable:** pct(pct: The percentage of the vote or support that the candidate received in the poll) \
- **numeric predictor:**\
 sample size(sample_size: The total number of respondents participating in the poll) \
 timegap(the time gap between the poll start date and the real election date i.e timegap = real US election date - poll start date) \
 pollscore(A numeric value representing the score or reliability of the pollster in question) \
- **categorical predictor**
state(The U.S. state where the poll was conducted or focused) \
methodology(The method used to conduct the poll)\

## Explore the data



## Measurement

In this dataset, each row represents a polling question that records the variables of interest. Each entry allows us to explore the real-world relationships between polling factors and the support percentage (`pct`) for the candidates Kamala Harris and Donald Trump. This dataset enables an analysis of how various polling characteristics influence the reported support levels for the candidates we are focused.


## Clean Data
The data cleaning process involves several steps to ensure the quality and relevance of the polling data. First, we filter the dataset to retain only poll results with a numeric grade of 2.7 or higher, indicating that the polls are considered reliable. Next, we address missing values in the state attribute: polls with NA in the state column are considered national polls.

We then create a new attribute, days_taken_from_election, which represents the time gap between the poll's start date and the actual U.S. election date. Additionally, we filter the dataset to include only polls conducted after July 21, 2024, the date when Kamala Harris declared her candidacy. Finally, we remove any remaining rows that contain missing values to ensure a clean dataset.

```{r}
#| label: tbl-cleaned-data
#| tbl-cap: Sample of cleaned US election data 
#| echo: false
#| warning: false
cleaned_data = read_csv(here("data/02-analysis_data/cleaned_data.csv"))

cleaned_data |>
  select(pct, sample_size, pollscore, days_taken_from_election, state, methodology, candidate_name) |>
  head(6) |>
  kable(
    col.names = c("pct", "sample_size", "pollscore", "days_taken_from_election","state", "methodology", "candidate_name"),
    booktabs = TRUE
    ) 
```


## Basic Statistics Summary for Data

```{r}
#| label: fig-clean-data-histogram-Harris-Trump
#| fig-cap: the average PCT vs State for Harris and Trump
#| echo: false
#| warning: false
#| fig-subcap: ["average PCT vs State for Harris","PCT vs State for Trump"]
#| layout-nrow: 2
#| fig-width: 40
#| fig-height: 20
Harris_data = cleaned_data[cleaned_data$candidate_name == "Kamala Harris", ]
Harris_data |>
  group_by(state) |>
  summarise(avg_pct = mean(pct, na.rm = TRUE)) |>
  ggplot(mapping = aes(x = state, y = avg_pct)) + 
  geom_col()  +
  theme_minimal() +
  labs(
    x = "State", y = "support percentage(pct)", title = "average support percentage(pct) for Harris per state"
  )


Trump_data = cleaned_data[cleaned_data$candidate_name == "Donald Trump", ]
Trump_data |>
  group_by(state) |>
  summarise(avg_pct = mean(pct, na.rm = TRUE)) |>
  ggplot(mapping = aes(x = state, y = avg_pct)) + 
  geom_col()  +
  theme_minimal() +
  labs(
    x = "State", y = "support percentage(pct)", title = "average support percentage(pct) for Harris per state"
  )


# cleaned_data %>%
#   mutate(month = factor(month, levels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
#                                           "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))) %>%
#   ggplot(mapping = aes(x = month, y = total_decedents)) + 
#   geom_bar(stat = "identity") +
#   theme_minimal() +
#   labs(
#     x = "Month", 
#     y = "Total Decedents"
#   )
```


# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.
us

## Basic Model
```{r}
just_harris_data = Harris_data |> na.omit()
model_MLR = lm(pct ~ pollscore + days_taken_from_election + methodology, data = just_harris_data)
summary(model_MLR)
just_harris_data <- just_harris_data |> mutate(fitted_value = predict(model_MLR),  num_harris = round((pct / 100) * sample_size, 0))

predictions = predict(model_MLR, just_harris_data)

ggplot(just_harris_data, aes(x = end_date)) +
  geom_point(aes(y = pct), color = "black") +
  geom_line(aes(y = fitted_value), color = "blue", linetype = "dotted") +
  facet_wrap(vars(methodology)) +
  theme_classic() +
  labs(y = "Harris percent", x = "Date", title = "Linear Model: pct ~ end_date + pollster")
```

```{r}
baye_model_data = just_harris_data
baye_model_data$pct = as.factor(baye_model_data$pct)
baye_model_data$pollscore = as.factor(baye_model_data$pollscore)
baye_model_data$days_taken_from_election = as.factor(baye_model_data$days_taken_from_election)
baye_model_data$methodology = as.factor(baye_model_data$methodology)
baye_model_data$pct <- as.numeric(baye_model_data$pct)
# Define the Bayesian model with brms

formula <- pct ~ pollscore + days_taken_from_election + (1 | methodology) + (1 | state)

priors = normal(0, 2.5, autoscale = TRUE)

bayesian_model_1 <- stan_glmer(
  formula = formula,
  data = just_harris_data,
  family = gaussian(),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  cores = 4,
  adapt_delta = 0.95
)
pp_check(bayesian_model_1)
summary(bayesian_model_1)

# Plot random effects
plot(bayesian_model_1, pars = "(Intercept)", prob = 0.95)

```

```{r}

```

```{r}


# Transform Biden and Trump’s vote shares to fit a beta distribution
# Biden received 51.3%, Trump received 46.8%, totaling to approximately 98.1% (adjusted here for simplicity)
total_votes <- 100
biden_shape1 <- 51.3 / total_votes * 10
biden_shape2 <- (1 - 51.3 / total_votes) * 10
trump_shape1 <- 46.8 / total_votes * 10
trump_shape2 <- (1 - 46.8 / total_votes) * 10

# Set up priors using beta distributions based on 2020 vote shares
prior <- c(
  set_prior(paste0("beta(", biden_shape1, ", ", biden_shape2, ")"), class = "b", coef = "biden"),
  set_prior(paste0("beta(", trump_shape1, ", ", trump_shape2, ")"), class = "b", coef = "trump")
)

# Define the model formula
formula <- pct ~ pollscore + days_taken_from_election + methodology

# Run the Bayesian model
model <- brm(
  formula = formula,
  data = baye_model_data,
  family = categ0orical(),
  prior = prior,
  chains = 4,
  iter = 2000,
  warmup = 1000,
  cores =4
)

# Summarize the model
summary(model)

```


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

# FiveThirtyEight Licenses
[FiveThirtyEight's data sets](https://github.com/fivethirtyeight/data/tree/master/polls) are used and modified by us under the [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).

\newpage


# References


